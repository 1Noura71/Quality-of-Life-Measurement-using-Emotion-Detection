{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0879533a",
   "metadata": {},
   "source": [
    "## Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8810276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp \n",
    "import cv2\n",
    "import csv \n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51363460",
   "metadata": {},
   "source": [
    "### Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38b78c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fer13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b68c4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2590c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7e6e2",
   "metadata": {},
   "source": [
    "### Fit and Evaluate Different Models using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a6456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'ridge': make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'randomForest':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'svm':make_pipeline(StandardScaler(), SVC()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa3f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train.values, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fee321d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 0.660548183058415\n",
      "randomForest 0.5540121542850056\n",
      "svm 0.5847699367481086\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test.values)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219e103",
   "metadata": {},
   "source": [
    "### Save and Load The Model with The Best Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a1d632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emotion_detection_rg1.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['ridge'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "448c14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emotion_detection_rg1.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d516ef",
   "metadata": {},
   "source": [
    "### Real-time Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3aee78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the landmarks drawing utilites \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# mediapipe landmark detection models\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "  # looping through each frame recived from the webcam\n",
    "  while (capture.isOpened()):\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # convert image color format from BGR to RGB \n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # pass the image to medipipe for detection \n",
    "    results = holistic.process(image)\n",
    "\n",
    "    #convert the image color format back to BGR for rendering \n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "  # Draw face laandmarks \n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                              mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                              mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                              )\n",
    "    # Draw right hand laandmarks \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw left hand laandmarks \n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw pose laandmarks \n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "\n",
    "    # Export Coordinates\n",
    "    try:\n",
    "        # Extract pose landmarks\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row= list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility]for landmark in pose]).flatten())\n",
    "\n",
    "        # Extract face landmarks\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row= list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility]for landmark in face]).flatten())\n",
    "\n",
    "        # Concate rows\n",
    "        row = pose_row + face_row\n",
    "\n",
    "\n",
    "        # Make Detections\n",
    "        X = pd.DataFrame([row])\n",
    "        emotion_class = model.predict(X.values)[0]\n",
    "#         emotion_detection_prob = model.predict_proba(x.values)[0]\n",
    "\n",
    "#          Grab ear coords\n",
    "        coords = tuple(np.multiply(\n",
    "                        np.array(\n",
    "                            (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                            results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)\n",
    "                        ), [640,480]).astype(int))\n",
    "        \n",
    "        cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(emotion_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "        cv2.putText(image, emotion_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    cv2.imshow('Raw webcam Feed', image)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2b824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
